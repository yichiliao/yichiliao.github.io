---
title: "Outside-In: Visualizing Out-of-Sight Regions-of-Interest in a360 Video Using Spatial Picture-in-Picture Previews"
excerpt: "Outside-In is a visualization technique which re-introduces off-screen regions-of-interest (ROIs) into the main screen as spatial picture-in-picture (PIP) previews<br/><img src='/images/outsidein.png'><br><br>"
collection: portfolio
---

<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/XyN1TRUhelw" frameborder="0" allowfullscreen></iframe>

------

<small>360-degree video contains a full field of environmental content. However, browsing these videos, either on screens or through head-mounted displays (HMDs), users consume only a subset of the full field of view per a natural viewing experience. This causes a search problem when a region-of-interest (ROI) in a video is outside of the current field of view (FOV) on the screen, or users may search for non-existing ROIs. 

We propose Outside-In, a visualization technique which re-introduces off-screen regions-of-interest (ROIs) into the main screen as spatial picture-in-picture (PIP) previews. The geometry of the preview windows further encodes a ROI's relative location vis-a-vis the main screen view, allowing for effective navigation. In an 18-participant study, we compare Outside-In with traditional arrow-based guidance within three types of 360-degree video. Results show that Outside-In outperforms in regard to understanding spatial relationship, the storyline of the content and overall preference. Two applications are demonstrated for use with Outside-In in 360-degree video navigation with touchscreens, and live telepresence.
</small>

<img src='/images/dwellplusplus.png'>
<small>
Our haptic stimulation design consists of a short 10ms vibrotacile feedback that indicates a mode arriving and a break that separates consecutive modes. We first tested the effectiveness of 170ms 150ms, 130ms, 110ms intervals between modes for a 10-level selection. The results reveal that three-beat-per-chunk rhythm design, e.g., displaying longer 25ms vibration at the first of every three modes, could potentially bring higher accuracy. 
</small>

<img src='/images/dwell_vibpattern.png'>
<small>
The second user study reveals significant improvement where a 94.5% accuracy was achieved for a 10-level dwell++ select using the 170ms interval with 3-beat-per-chunk design, and a 93.82% accuracy using the faster 150ms interval with similar chunks for 5-level selection. 
</small>

<img src='/images/dwell_study3.png'>
<small>
The approximate performance of conducting touch and receiving vibration from different hands was investigated at the last study for providing a wider range of usage for Dwell++.
</small>

<img src='/images/dwell_applications.png'>

<small>
**Publication:** <br> 
Coming soon in Proc. UIST'17.
<br>Yi-Chi Liao, Yen-Chiu Chen, Liwei Chan, Bing-Yu Chen</small>