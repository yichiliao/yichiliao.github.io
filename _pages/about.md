---
permalink: /
title: ""
excerpt: "Yi-Chi Liao's homepage"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
# Moi! This is Yi-Chi!
<br>
<small>
I’m a PhD student at [Aalto University](https://www.aalto.fi/en) researching Computational Interaction as part of the [User Interfaces Group](http://userinterfaces.aalto.fi/), led by [Prof Antti Oulasvirta](http://users.comnet.aalto.fi/oulasvir/). Before this, I received my bachelor’s and master’s degree in Information Management at [National Taiwan University](https://www.ntu.edu.tw/english/). My interests are designing and building physical interfaces utilizing computational methods such as Bayesian data analysis, optimization, reinforcement learning, and meta-learning. My ultimate goal is to bring HCI one step closer to optimized touch and haptic interactions.  
</small>

<small>
I currently research in **assisting UI design via multi-objective Bayesian Optimization**, and **modelling how humans interact with physical interfaces with meta-reinforcement learning methods**. [My publications]((https://scholar.google.com/citations?user=Ddny4V4AAAAJ&hl=en)) are in peer-reviewed venues, including CHI, UIST, and SIGGRAPH, the top human-computer interaction venues from the ACM. 
</small>

<small>
I also lecture on various topics in Aalto, including input and sensing, Bayesian decoders, Bayesian data analysis, and Deep Learning. I am invited to review for multiple ACM conferences and IEEE journals. 
</small>

------

Selected Publications
======

<br>
**Button Simulation and Design via FDVV Models** *[CHI'20, 10-page Paper]*<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/gE7v3Ai5bFk" frameborder="0" allowfullscreen></iframe>

<small>
Designing a push-button with desired sensation and performance is challenging because the mechanical construction must have the right response characteristics. In this paper, we extend the typical force-displacement (FD) modeling to include vibration (V) and velocity-dependence characteristics (V). The resulting FDVV models better capture tactility characteristics of buttons. They increase the range of simulated buttons and the perceived realism relative to FD models. The paper also demonstrates methods for obtaining these models, editing them, and simulating accordingly. Our approach enables the analysis, prototyping, and optimization of buttons, and supports exploring designs that would be hard to implement mechanically.
</small>

<small>In Proc. CHI'20 // 
[[Project Page](https://yichiliao.github.io/portfolio/0-buttondesign/)], [[Paper](http://yichiliao.github.io/files/dwellplus_uist17.pdf)], [[30s Video](https://www.youtube.com/watch?v=gE7v3Ai5bFk)], [[Full Video](https://www.youtube.com/watch?v=hOi_7O7USaI)]. </small>

------

<br>
**Dwell+: Multi-Level Mode Selection Using Vibrotactile Cues** *[UIST'17, 10-page Paper]*<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/E90wT4RwuSk" frameborder="0" allowfullscreen></iframe>

<small>
This paper presents Dwell+, a method that boosts the effectiveness of typical dwell select by augmenting the passive dwell duration with active haptic ticks which promptly drives rapid switches of modes forward through the user's skin sensation. Dwell+ enables multi-level dwell select using rapid haptic ticks. To select a mode from a button, users dwell-touch the button until the mode of selection being haptically prompted. Applications demonstrated implementing Dwell+ across different interfaces; ranging from vibration-enabled touchscreens to non-vibrating interfaces. 
</small>

<small>In Proc. UIST'17 // 
[[Project Page](https://yichiliao.github.io/portfolio/1-dwellplus/)], [[Paper](http://yichiliao.github.io/files/dwellplus_uist17.pdf)], [[30s Video](https://youtu.be/E90wT4RwuSk)], [[Full Video](https://www.youtube.com/watch?v=SHxr5JcYqy8)]. </small>

------

<br>
**Outside-In: Visualizing Out-of-Sight Region-of-Interests in a 360 Video Using Spatial Picture-in-Picture Previews** <br>*[UIST'17, 9-page Paper]*<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/XyN1TRUhelw" frameborder="0" allowfullscreen></iframe>

<small>
We propose Outside-In, a visualization technique which re-introduces off-screen ROIs into the main screen as spatialpicture-in-picture (PIP) previews. The geometry of the pre-view windows further encodes the ROIs’ relative directions tothe main screen view, allowing for effective navigation. 
</small>

<small>In Proc. UIST'17 // 
[[Project Page](https://yichiliao.github.io/portfolio/2-outsidein/)], [[Paper](http://yichiliao.github.io/files/outsidein_uist17.pdf)], [[Video](https://www.youtube.com/watch?v=XyN1TRUhelw)].
</small>

------

<br>
**EdgeVib: Effective Alphanumeric Character Output Using a Wrist-Worn Tactile Display.** *[UIST'16, 6-page Paper]*<br>

<small>Yi-Chi Liao, Yi-Ling Chen, Jo-Yu Lo, Rong-Hao Liang, Liwei Chan, Bing-Yu Chen</small>

<iframe width="560" height="315" src="https://www.youtube.com/embed/Q_2owlSeDg4" frameborder="0" allowfullscreen></iframe>

<small>
"Transferring rich spatialtemporal tactile messages while retaining the recognition rates" has been a major challenge in the development of tactile displays. We present EdgeVib, a set of multistroke alphanumeric patterns based on EdgeWrite. Learning these patterns takes comparable period to learning Graffiti (15min), while the recognition rates achive 85.9% and 88.6% for alphabet and digits respectively.
</small>

<small>In Proc. UIST'16 // 
[[Project Page](https://yichiliao.github.io/portfolio/3-edgevib/)], [[Paper](https://yichiliao.github.io/files/edgevib_uist16.pdf)], [[Video](https://www.youtube.com/watch?v=Q_2owlSeDg4)]. </small>

------

**ThirdHand: Wearing a Robotic Arm to Experience Rich Force Feedback.** *[Siggraph Asia'15 Emerging Technology]*<br> 

<small>Yi-Chi Liao, Shun-Yao Yang, Rong-Hao Liang, Liwei Chan, Bing-Yu Chen</small>

<iframe width="560" height="315" src="https://www.youtube.com/embed/sVRI0L7xu7E" frameborder="0" allowfullscreen></iframe>

<small>
ThirdHnad is a wearable robotic arm provides 5-DOF force feedback to enrich the mobile gaming experience. Comparing to traditional mounted-on-environment force-feedback devices such as phantom, ThirdHand provides higher mobility due to its wearable form. Also, comparing to the muscle-propelled and gyro-effect solutions, our approach enables more accurate control with stronger forces.
</small>

<small>In Proc. Siggraph Asia'15 Emerging Technology // 
[[Project Page](https://yichiliao.github.io/portfolio/5-thirdhand/)], [[Paper](http://yichiliao.github.io/files/thirdhand_sa15.pdf)], [[Video](https://www.youtube.com/watch?v=sVRI0L7xu7E)]. </small>

------



Academic Services
======

<small>
**Organizing Committee** <br>
ACM CHI 2022 Video Preview Chair<br>
<br>
**Program Committee** <br>
ACM CHI 2021 Late-Breaking Work<br>
<br>

<small>
**Paper Review** <br>
IEEE Transactions on Haptics: 2019, 2021<br>
International Journal of Human - Computer Studies: 2021<br>
IEEE Haptics Symposium: 2020<br>
ACM CHI: 2016-2021 <br>
ACM MobileHCI: 2017-2020 <br>
ACM TEI: 2017-2018<br>
ACM UbiComp/ISWC: 2017<br>
Augmented Human: 2016-2017<br>
</small>
<br>
<small>
**Special Recognitions for Outstanding Reviews:** <br>
1 x recognition for CHI 2020 Papers <br>
3 x recognition for CHI 2021 Papers <br>
</small>

------

Other Activities
======

<small>
In 2020, I gave a lecture about **Bayesian Statistics** and its applications in _User Research_ course, Aalto University (by PhD. Aurélien Nioche). I also gave a lecture on **Deep Learning** in _Computational User Interface Design_, Aalto University (by Prof. Antti Oulasvirta).
</small>

<small>
In 2019, I gave a lecture in _Computational User Interface Design_ course, Aalto University (by Prof. Antti Oulasvirta) for introducing **Probilistic Decoding**. In another course, _Engineering for Humans_, Aalto University (by Prof. Antti Oulasvirta), I talked about **Input Sensing Pipeline and Data Processing**.
</small>

<small>
During 2014 to 2016, I've been a teaching assistant of _Introduction to HCI_ (lectured by [Prof. Rong-Hao Liang](http://www.cmlab.csie.ntu.edu.tw/~howieliang/) and [Prof. Bing-Yu Chen](https://www.cmlab.csie.ntu.edu.tw/~robin/)), and _Computer Architecture_ (lectured by [Prof. Bing-Yu Chen](https://www.cmlab.csie.ntu.edu.tw/~robin/)) in National Taiwan University.
</small>

<small>
I also student volunteered at _Siggraph Aisa 2016_, and held the biggest HCI workshop in Taiwan, _[OpenHCI'15](http://www.openhci.com/2015/index.html)_ and _[OpenHCI'16](http://www.openhci.com/2016/index.html)_. I also organized the other workshop, _[HoCuIn'17](https://hocuin2017.wordpress.com/)_, to introduce more research-oriented HCI to gruaduate students in Taiwan.
</small>
